{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab7_deepmoji.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF_5Fawwb2n2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip3 uninstall -y tensorflow\n",
        "# !pip3 install tensorflow==2.1.0\n",
        "# %tensorflow_version 2.x\n",
        "!git clone https://github.com/bfelbo/DeepMoji.git\n",
        "%cd DeepMoji/\n",
        "#!python setup.py install --user\n",
        "#%cd DeepMoji\n",
        "!python scripts/download_weights.py\n",
        "# import tensorflow as tf\n",
        "# print(tf.__version__)\n",
        "!pip install numpy==1.16.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QADX1I_2b49h",
        "colab_type": "code",
        "outputId": "9d26202d-910a-4558-d581-0c4a6f14c04e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd DeepMoji/examples/\n",
        "!ls\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from __future__ import print_function\n",
        "import example_helper\n",
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from keras.datasets import imdb\n",
        "from deepmoji.model_def import deepmoji_emojis\n",
        "from deepmoji.global_variables import PRETRAINED_PATH, VOCAB_PATH\n",
        "from keras.layers import Flatten, Dense, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "EPOCHS_NUMBER=10\n",
        "\n",
        "# Seed for reproducibility\n",
        "np.random.seed(1337)\n",
        "\n",
        "nb_tokens = 20000\n",
        "maxlen = 80\n",
        "batch_size = 512\n",
        "\n",
        "print('Loading data...')\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=nb_tokens)\n",
        "print(len(X_train), 'train sequences')\n",
        "print(len(X_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "\n",
        "print('Build model...')\n",
        "model = deepmoji_emojis(maxlen, PRETRAINED_PATH)\n",
        "model.summary()\n",
        "print(model.layers)\n",
        "# model.trainable = False\n",
        "# for layer in model.layers:\n",
        "#     layer.trainable = False\n",
        "x = model.layers[-2].output\n",
        "x = Dense(1024)(x)\n",
        "x = Dropout(1024)(x)\n",
        "x = Dense(1024)(x)\n",
        "x = Dropout(1024)(x)\n",
        "predictions = Dense(1, activation = \"sigmoid\")(x)\n",
        "model = Model(inputs = model.input, outputs = predictions)\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=EPOCHS_NUMBER)\n",
        "\n",
        "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeepMoji/examples\n",
            "create_twitter_vocab.py\t\t  finetune_youtube_last.py\n",
            "dataset_split.py\t\t  imdb_from_scratch.py\n",
            "encode_texts.py\t\t\t  __init__.py\n",
            "example_helper.py\t\t  README.md\n",
            "example_helper.pyc\t\t  score_texts_emojis.py\n",
            "finetune_insults_chain-thaw.py\t  tokenize_dataset.py\n",
            "finetune_semeval_class-avg_f1.py  vocab_extension.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "Loading data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0322 19:26:37.603610 140094240921472 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0322 19:26:37.605323 140094240921472 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0322 19:26:37.607842 140094240921472 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (25000, 80)\n",
            "X_test shape: (25000, 80)\n",
            "Build model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0322 19:26:38.826596 140094240921472 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:2974: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0322 19:26:40.549773 140094240921472 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0322 19:26:40.550759 140094240921472 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0322 19:26:40.553608 140094240921472 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0322 19:26:40.698369 140094240921472 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "W0322 19:26:40.700021 140094240921472 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "W0322 19:26:40.757635 140094240921472 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "W0322 19:26:41.485275 140094240921472 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0322 19:26:41.503967 140094240921472 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 80)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 80, 256)      12800000    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 80, 256)      0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bi_lstm_0 (Bidirectional)       (None, 80, 1024)     3149824     activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bi_lstm_1 (Bidirectional)       (None, 80, 1024)     6295552     bi_lstm_0[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 80, 2304)     0           bi_lstm_1[0][0]                  \n",
            "                                                                 bi_lstm_0[0][0]                  \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "attlayer (AttentionWeightedAver (None, 2304)         2304        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Dense)                 (None, 64)           147520      attlayer[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 22,395,200\n",
            "Trainable params: 22,395,200\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "[<keras.engine.input_layer.InputLayer object at 0x7f6a1c673c10>, <keras.layers.embeddings.Embedding object at 0x7f6a1c683c50>, <keras.layers.core.Activation object at 0x7f6a1c683c90>, <keras.layers.wrappers.Bidirectional object at 0x7f69dacb6250>, <keras.layers.wrappers.Bidirectional object at 0x7f69daba39d0>, <keras.layers.merge.Concatenate object at 0x7f69dab24a50>, <deepmoji.attlayer.AttentionWeightedAverage object at 0x7f69daa0fa10>, <keras.layers.core.Dense object at 0x7f69daa05e50>]\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 80)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 80, 256)      12800000    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 80, 256)      0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bi_lstm_0 (Bidirectional)       (None, 80, 1024)     3149824     activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bi_lstm_1 (Bidirectional)       (None, 80, 1024)     6295552     bi_lstm_0[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 80, 2304)     0           bi_lstm_1[0][0]                  \n",
            "                                                                 bi_lstm_0[0][0]                  \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "attlayer (AttentionWeightedAver (None, 2304)         2304        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1024)         2360320     attlayer[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            1025        dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 25,658,625\n",
            "Trainable params: 25,658,625\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0322 19:26:43.684921 140094240921472 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W0322 19:26:43.882355 140094240921472 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 86s 3ms/step - loss: 0.6252 - acc: 0.6452\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 81s 3ms/step - loss: 0.2602 - acc: 0.9043\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 81s 3ms/step - loss: 0.0560 - acc: 0.9886\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 81s 3ms/step - loss: 0.0297 - acc: 0.9974\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 81s 3ms/step - loss: 0.0283 - acc: 0.9970\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 81s 3ms/step - loss: 0.0252 - acc: 0.9987\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 81s 3ms/step - loss: 0.0317 - acc: 0.9970\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 81s 3ms/step - loss: 0.0247 - acc: 0.9984\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 81s 3ms/step - loss: 0.0214 - acc: 0.9996\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 81s 3ms/step - loss: 0.0214 - acc: 0.9995\n",
            "25000/25000 [==============================] - 24s 977us/step\n",
            "Test score: 1.368722240524292\n",
            "Test accuracy: 0.8131199998664856\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}